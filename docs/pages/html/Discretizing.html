

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Discretizing &mdash; bnlearn bnlearn documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/css/custom.css?v=e0179649" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=441dd29d"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Causation" href="Structure%20learning.html" />
    <link rel="prev" title="Install from Pypi (pip)" href="Installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            bnlearn
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
    
              <p class="caption" role="heading"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="Quickstart.html">Quickstart</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Installation.html">Install from Pypi (pip)</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html#install-from-github">Install from github</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html#create-environment">Create environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html#uninstall">Uninstall</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html#validate">Validate</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html#import-error">Import Error</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Discretizing</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Discretizing</a></li>
<li class="toctree-l1"><a class="reference internal" href="#discretize-manually">Discretize manually</a></li>
<li class="toctree-l1"><a class="reference internal" href="#discretize-automatically-probability-density">Discretize Automatically: Probability Density</a></li>
<li class="toctree-l1"><a class="reference internal" href="#discretize-automatically-principled-bayesian">Discretize Automatically: Principled Bayesian</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#structure-learning">Structure learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#parameter-learning">Parameter learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#inferences">Inferences</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Structure learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Structure%20learning.html">Causation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Structure%20learning.html#exhaustivesearch">Exhaustivesearch</a></li>
<li class="toctree-l1"><a class="reference internal" href="Structure%20learning.html#hillclimbsearch">Hillclimbsearch</a></li>
<li class="toctree-l1"><a class="reference internal" href="Structure%20learning.html#chow-liu">Chow-liu</a></li>
<li class="toctree-l1"><a class="reference internal" href="Structure%20learning.html#tree-augmented-naive-bayes-tan">Tree-augmented Naive Bayes (TAN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="Structure%20learning.html#naivebayes">NaiveBayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="Structure%20learning.html#constraint-based">Constraint-based</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parameter learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Parameter%20learning.html">Parameter learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Parameter%20learning.html#maximum-likelihood-estimation">Maximum Likelihood Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Parameter%20learning.html#bayesian-parameter-estimation">Bayesian Parameter Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Parameter%20learning.html#examples-parameter-learning">Examples Parameter learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Parameter%20learning.html#conditional-probability-distributions-cpd">Conditional Probability Distributions (CPD)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="Inference.html#inference-algorithms">Inference Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="Inference.html#examples-inference">Examples Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Continuous Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Continuous%20Data.html">Modelling Continuous Datasets</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Predict</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Predict.html">Predict</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Sampling</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Sampling.html">Forward Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sampling.html#gibbs-sampling">Gibbs Sampling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Plot</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Plot.html">Interactive plot</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plot.html#static-plot-networkx">Static plot (networkx)</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plot.html#static-plot-graphviz">Static plot (graphviz)</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plot.html#comparison-of-two-networks">Comparison of two networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plot.html#node-properties">Node properties</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plot.html#edge-properties">Edge properties</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other functionalities</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="independence_test.html">Independence test</a></li>
<li class="toctree-l1"><a class="reference internal" href="Create%20DAG.html">Directed Acyclic Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="impute.html">Impute</a></li>
<li class="toctree-l1"><a class="reference internal" href="Example%20Datasets.html">DataFrames</a></li>
<li class="toctree-l1"><a class="reference internal" href="Example%20Datasets.html#import-dag-bif">Import DAG/BIF</a></li>
<li class="toctree-l1"><a class="reference internal" href="Example%20Datasets.html#export-dag-bif">Export DAG/BIF</a></li>
<li class="toctree-l1"><a class="reference internal" href="whitelist_blacklist.html">Black and white lists</a></li>
<li class="toctree-l1"><a class="reference internal" href="topological_sort.html">Topological sort</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataframe%20conversions.html">Data Conversions</a></li>
<li class="toctree-l1"><a class="reference internal" href="Structure_scores.html">Structure Scores</a></li>
<li class="toctree-l1"><a class="reference internal" href="saving%20and%20loading.html">Saving and Loading</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Examples.html">Start with RAW data</a></li>
<li class="toctree-l1"><a class="reference internal" href="Examples.html#structure-learning">Structure learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Examples.html#parameter-learning">Parameter learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Examples.html#create-a-bayesian-network-learn-its-parameters-from-data-and-perform-the-inference">Create a Bayesian Network, learn its parameters from data and perform the inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="UseCases.html">Use Case Titanic</a></li>
<li class="toctree-l1"><a class="reference internal" href="UseCases.html#use-case-medical-domain">Use Case Medical domain</a></li>
<li class="toctree-l1"><a class="reference internal" href="UseCases.html#use-case-continuous-datasets">Use Case Continuous Datasets</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parameters and attributes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="bnlearn.structure_learning.html">bnlearn.structure_learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="bnlearn.parameter_learning.html">bnlearn.parameter_learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="bnlearn.inference.html">bnlearn.inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="bnlearn.bnlearn.html">bnlearn.bnlearn</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html">Sponsor</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#medium-blog">Medium Blog</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#github">Github</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#colab-notebook">Colab Notebook</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#citing">Citing</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#references">References</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#related-packages">Related Packages</a></li>
</ul>

    <a href= "genindex.html">Index</a>
  
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">bnlearn</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Discretizing</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/Discretizing.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="discretizing">
<h1>Discretizing<a class="headerlink" href="#discretizing" title="Link to this heading"></a></h1>
<p>In <code class="docutils literal notranslate"><span class="pre">bnlearn</span></code> the following options are available to work with continuous datasets:</p>
<ul class="simple">
<li><ol class="arabic simple">
<li><p>Discretize continuous datasets manually using domain knowledge.</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="2">
<li><p>Discretize continuous datasets using a probability density fitting.</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="3">
<li><p>Discretize continuous datasets using a principled Bayesian discretization method.</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="4">
<li><p>Model continuous and hybrid datasets in a semi-parametric approach that assumes a linear relationships.</p></li>
</ol>
</li>
</ul>
</section>
<section id="discretize-manually">
<h1>Discretize manually<a class="headerlink" href="#discretize-manually" title="Link to this heading"></a></h1>
<p>Discretizing continuous datasets manually using domain knowledge involves dividing a continuous variable into a set of discrete intervals based on an understanding of the data’s context and the relationships between variables. This method allows for meaningful groupings of data points, which can simplify analysis and improve interpretability in models.</p>
<p>By leveraging expertise in the subject matter, the intervals or thresholds can be chosen to reflect real-world significance, such as categorizing weather conditions into meaningful ranges (e.g., “freezing,” “warm,” “hot”). This approach contrasts with automatic binning methods (as depicted in approach 2), such as equal-width or equal-frequency binning, where intervals may not correspond to meaningful domain-specific boundaries.</p>
<p>For instance, lets load the auto mpg data set and based on automotive standards, we can define horsepower categories:</p>
<ul class="simple">
<li><p>Low: Cars with horsepower less than 100 (typically small, fuel-efficient cars)</p></li>
<li><p>Medium: Cars with horsepower between 100 and 150 (moderate performance cars)</p></li>
<li><p>High: Cars with horsepower above 150 (high-performance vehicles)</p></li>
</ul>
<p>After all continuous variables are catagorized, the normal structure learning procedure can be applied.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">bnlearn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">bn</span>

<span class="c1"># Load data set</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">import_example</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="s1">&#39;auto_mpg&#39;</span><span class="p">)</span>

<span class="c1"># Print</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="c1">#       mpg  cylinders  displacement  ...  acceleration  model_year  origin</span>
<span class="c1"># 0    18.0          8         307.0  ...          12.0          70       1</span>
<span class="c1"># 1    15.0          8         350.0  ...          11.5          70       1</span>
<span class="c1"># 2    18.0          8         318.0  ...          11.0          70       1</span>
<span class="c1"># 3    16.0          8         304.0  ...          12.0          70       1</span>
<span class="c1"># 4    17.0          8         302.0  ...          10.5          70       1</span>
<span class="c1"># ..    ...        ...           ...  ...           ...         ...     ...</span>
<span class="c1"># 387  27.0          4         140.0  ...          15.6          82       1</span>
<span class="c1"># 388  44.0          4          97.0  ...          24.6          82       2</span>
<span class="c1"># 389  32.0          4         135.0  ...          11.6          82       1</span>
<span class="c1"># 390  28.0          4         120.0  ...          18.6          82       1</span>
<span class="c1"># 391  31.0          4         119.0  ...          19.4          82       1</span>
<span class="c1">#</span>
<span class="c1"># [392 rows x 8 columns]</span>

<span class="c1"># Define horsepower bins based on domain knowledge</span>
<span class="n">bins</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;horsepower&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;low&#39;</span><span class="p">,</span> <span class="s1">&#39;medium&#39;</span><span class="p">,</span> <span class="s1">&#39;high&#39;</span><span class="p">]</span>

<span class="c1"># Discretize horsepower using the defined bins</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;horsepower_category&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;horsepower&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">include_lowest</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;horsepower&#39;</span><span class="p">,</span> <span class="s1">&#39;horsepower_category&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="c1">#    horsepower horsepower_category</span>
<span class="c1"># 0       130.0              medium</span>
<span class="c1"># 1       165.0                high</span>
<span class="c1"># 2       150.0              medium</span>
<span class="c1"># 3       150.0              medium</span>
<span class="c1"># 4       140.0              medium</span>
</pre></div>
</div>
</section>
<section id="discretize-automatically-probability-density">
<h1>Discretize Automatically: Probability Density<a class="headerlink" href="#discretize-automatically-probability-density" title="Link to this heading"></a></h1>
<p>In contradiction to manual discretizing variables, we can also automatically determine the best binning per variable. However, such approaches require extra attention in contrast with manual binning methods, where intervals may not correspond to meaningful domain-specific boundaries. To automatically create more meaningful bins than simple equal-width or equal-frequency binning, we can determine the distribution that best fits the signal and then use the 95% confidence interval to create low, medium, and high categories.</p>
<p>In addition, it is always wise to also have a visual inspection of the distribution plots with the threshold that is determined for the binning. In such a manner you can decide whether the low-end, medium, and high-end is a meaningful threshold. As an example, if we take acceleration and perform this approach, we find a low-end of 8 seconds to ~11 seconds which will represent the fast cars. On the high end are the slow cars with an acceleration of 20 seconds to 24 seconds. The remaining cars fall in the category normal. This seems very plausible so we can continue with these categories. See the code block below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import library</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">distfit</span><span class="w"> </span><span class="kn">import</span> <span class="n">distfit</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize and set 95% CII</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">distfit</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

<span class="c1"># Fit Transform</span>
<span class="n">dist</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;acceleration&#39;</span><span class="p">])</span>

<span class="c1"># Make plot</span>
<span class="n">dist</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">bins</span> <span class="o">=</span> <span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;acceleration&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">dist</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="s1">&#39;CII_min_alpha&#39;</span><span class="p">],</span> <span class="n">dist</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="s1">&#39;CII_max_alpha&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;acceleration&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()]</span>

<span class="c1"># Discretize acceleration using the defined bins</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;acceleration_category&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;acceleration&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;fast&#39;</span><span class="p">,</span> <span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="s1">&#39;slow&#39;</span><span class="p">],</span> <span class="n">include_lowest</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">del</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;acceleration&#39;</span><span class="p">]</span>
</pre></div>
</div>
<table class="docutils align-center">
<tbody>
<tr class="row-odd"><td><p><img alt="figd1a" src="_images/dist1.png" /></p></td>
</tr>
</tbody>
</table>
<p>In case there are multiple continuous variables, we can also automate the distribution fitting:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># For all remaining columns, the same approach can be performed:</span>
<span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;mpg&#39;</span><span class="p">,</span> <span class="s1">&#39;displacement&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">]</span>

<span class="c1"># Do for every variable</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
    <span class="c1"># Initialize and set 95% CII</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">distfit</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>

    <span class="c1"># Make plot</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">bins</span> <span class="o">=</span> <span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">dist</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="s1">&#39;CII_min_alpha&#39;</span><span class="p">],</span> <span class="n">dist</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="s1">&#39;CII_max_alpha&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()]</span>

    <span class="c1"># Discretize acceleration using the defined bins</span>
    <span class="n">df</span><span class="p">[</span><span class="n">col</span> <span class="o">+</span> <span class="s1">&#39;_category&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;low&#39;</span><span class="p">,</span> <span class="s1">&#39;medium&#39;</span><span class="p">,</span> <span class="s1">&#39;high&#39;</span><span class="p">],</span> <span class="n">include_lowest</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">del</span> <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span>
</pre></div>
</div>
<p>After all continuous variables are categorized, the causal discovery approach for structure learning can be applied.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Structure learning</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">structure_learning</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">methodtype</span><span class="o">=</span><span class="s1">&#39;hc&#39;</span><span class="p">)</span>

<span class="c1"># Compute edge strength</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">independence_test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>

<span class="c1"># Make plot and put the -log10(pvalues) on the edges</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">edge_labels</span><span class="o">=</span><span class="s1">&#39;pvalue&#39;</span><span class="p">)</span>

<span class="n">dotgraph</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">plot_graphviz</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">edge_labels</span><span class="o">=</span><span class="s1">&#39;pvalue&#39;</span><span class="p">)</span>
<span class="n">dotgraph</span>
</pre></div>
</div>
<table class="docutils align-center">
<tbody>
<tr class="row-odd"><td><p><img alt="figd2a" src="_images/auto_mpg_distfit.png" /></p></td>
</tr>
</tbody>
</table>
</section>
<section id="discretize-automatically-principled-bayesian">
<h1>Discretize Automatically: Principled Bayesian<a class="headerlink" href="#discretize-automatically-principled-bayesian" title="Link to this heading"></a></h1>
<p>Automatic discritizing datasets is accomplished by using a principled Bayesian discretization method.
The method is created by Yi-Chun Chen et al <a class="footnote-reference brackets" href="#id3" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> in Julia <a class="footnote-reference brackets" href="#id4" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>. The code is ported to Python and is now part of <code class="docutils literal notranslate"><span class="pre">bnlearn</span></code>.
Yi-Chun Chen demonstrates that his proposed method is superior to the established minimum description length algorithm.</p>
<p>A disadvantage of this approach is that you need to pre-define the edges before you can apply the discritization method.
The underlying idea is that after applying this discritization method, structure learning approaches can then be applied.
To demonstrate the usage of automatically discritizing continuous data, lets use the <strong>auto mpg</strong> dataset again.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">bnlearn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">bn</span>

<span class="c1"># Load data set</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">import_example</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="s1">&#39;auto_mpg&#39;</span><span class="p">)</span>
<span class="c1"># Print</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1">#       mpg  cylinders  displacement  ...  acceleration  model_year  origin</span>
<span class="c1"># 0    18.0          8         307.0  ...          12.0          70       1</span>
<span class="c1"># 1    15.0          8         350.0  ...          11.5          70       1</span>
<span class="c1"># 2    18.0          8         318.0  ...          11.0          70       1</span>
<span class="c1"># 3    16.0          8         304.0  ...          12.0          70       1</span>
<span class="c1"># 4    17.0          8         302.0  ...          10.5          70       1</span>
<span class="c1"># ..    ...        ...           ...  ...           ...         ...     ...</span>
<span class="c1"># 387  27.0          4         140.0  ...          15.6          82       1</span>
<span class="c1"># 388  44.0          4          97.0  ...          24.6          82       2</span>
<span class="c1"># 389  32.0          4         135.0  ...          11.6          82       1</span>
<span class="c1"># 390  28.0          4         120.0  ...          18.6          82       1</span>
<span class="c1"># 391  31.0          4         119.0  ...          19.4          82       1</span>
<span class="c1">#</span>
<span class="c1"># [392 rows x 8 columns]</span>

<span class="c1"># Define the edges</span>
<span class="n">edges</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;cylinders&quot;</span><span class="p">,</span> <span class="s2">&quot;displacement&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;displacement&quot;</span><span class="p">,</span> <span class="s2">&quot;model_year&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;displacement&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;displacement&quot;</span><span class="p">,</span> <span class="s2">&quot;horsepower&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="s2">&quot;model_year&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="s2">&quot;mpg&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;horsepower&quot;</span><span class="p">,</span> <span class="s2">&quot;acceleration&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;mpg&quot;</span><span class="p">,</span> <span class="s2">&quot;model_year&quot;</span><span class="p">),</span>
<span class="p">]</span>

<span class="c1"># Create DAG based on edges</span>
<span class="n">DAG</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">make_DAG</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span>

<span class="c1"># Plot the DAG</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">DAG</span><span class="p">)</span>

<span class="c1"># Plot the DAG using graphviz</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot_graphviz</span><span class="p">(</span><span class="n">DAG</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-default" id="fig-auto-mpg-dag-edges">
<img alt="_images/auto_mpg_DAG_edges.png" src="_images/auto_mpg_DAG_edges.png" />
</figure>
<p>We can now discretize the continuous columns as following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># A good habbit is to set the columns with continuous data as float</span>
<span class="n">continuous_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;mpg&quot;</span><span class="p">,</span> <span class="s2">&quot;displacement&quot;</span><span class="p">,</span> <span class="s2">&quot;horsepower&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="s2">&quot;acceleration&quot;</span><span class="p">]</span>

<span class="c1"># Discretize the continous columns by specifying</span>
<span class="n">df_discrete</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">discretize</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">continuous_columns</span><span class="p">,</span> <span class="n">max_iterations</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1">#                 mpg  cylinders  ... model_year origin</span>
<span class="c1"># 0     (17.65, 21.3]          8  ...         70      1</span>
<span class="c1"># 1    (8.624, 15.25]          8  ...         70      1</span>
<span class="c1"># 2     (17.65, 21.3]          8  ...         70      1</span>
<span class="c1"># 3    (15.25, 17.65]          8  ...         70      1</span>
<span class="c1"># 4    (15.25, 17.65]          8  ...         70      1</span>
<span class="c1"># ..              ...        ...  ...        ...    ...</span>
<span class="c1"># 387   (25.65, 28.9]          4  ...         82      1</span>
<span class="c1"># 388    (28.9, 46.6]          4  ...         82      2</span>
<span class="c1"># 389    (28.9, 46.6]          4  ...         82      1</span>
<span class="c1"># 390   (25.65, 28.9]          4  ...         82      1</span>
<span class="c1"># 391    (28.9, 46.6]          4  ...         82      1</span>
<span class="c1">#</span>
<span class="c1"># [392 rows x 8 columns]</span>
</pre></div>
</div>
<p>At this point it is not different than any other discrete data set. We can specify the DAG together with the
discrete data frame and fit a model using <code class="docutils literal notranslate"><span class="pre">bnlearn</span></code>.</p>
<section id="structure-learning">
<h2>Structure learning<a class="headerlink" href="#structure-learning" title="Link to this heading"></a></h2>
<p>We will learn the structure on the discretezed continuous data. Note that the data is also discretezed on a set of edges which may introduce a bias in the learned structure.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Learn the structure</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">structure_learning</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_discrete</span><span class="p">,</span> <span class="n">methodtype</span><span class="o">=</span><span class="s1">&#39;hc&#39;</span><span class="p">,</span> <span class="n">scoretype</span><span class="o">=</span><span class="s1">&#39;bic&#39;</span><span class="p">)</span>

<span class="c1"># Independence test</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">independence_test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">prune</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># [bnlearn] &gt;Compute edge strength with [chi_square]</span>
<span class="c1"># [bnlearn] &gt;Edge [weight &lt;-&gt; mpg] [P=0.999112] is excluded because it was not significant (P&lt;0.05) with [chi_square]</span>

<span class="c1"># Make plot</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">edge_labels</span><span class="o">=</span><span class="s1">&#39;pvalue&#39;</span><span class="p">)</span>

<span class="c1"># Make plot with graphviz</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot_graphviz</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">edge_labels</span><span class="o">=</span><span class="s1">&#39;pvalue&#39;</span><span class="p">)</span>

<span class="c1"># Create interactive plot</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">interactive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils align-center">
<tbody>
<tr class="row-odd"><td><p><img alt="fig2a" src="_images/fig2a.png" /></p></td>
</tr>
<tr class="row-even"><td><p><img alt="fig2b" src="_images/fig2b.png" /></p></td>
</tr>
</tbody>
</table>
<iframe src="https://erdogant.github.io/docs/d3blocks/bnlearn_continous_example_1.html" height="700px" width="750px", frameBorder="0"></iframe></section>
<section id="parameter-learning">
<h2>Parameter learning<a class="headerlink" href="#parameter-learning" title="Link to this heading"></a></h2>
<p>Let’s continue with parameter learning on the continuous data set and see whether we can estimate the CPDs.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit model based on DAG and discretized continous columns</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">parameter_learning</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">DAG</span><span class="p">,</span> <span class="n">df_discrete</span><span class="p">)</span>

<span class="c1"># Use MLE method</span>
<span class="c1"># model_mle = bn.parameter_learning.fit(DAG, df_discrete, methodtype=&quot;maximumlikelihood&quot;)</span>
</pre></div>
</div>
<p>After fitting the model on the DAG and data frame, we can perform the independence test to remove any spurious edges and
create a plot. In this case, the tooltips will contain the CPDs as these are computed with parameter learning.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Independence test</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">independence_test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">prune</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Make plot</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">edge_labels</span><span class="o">=</span><span class="s1">&#39;pvalue&#39;</span><span class="p">)</span>

<span class="c1"># Make plot graphviz</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot_graphviz</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">edge_labels</span><span class="o">=</span><span class="s1">&#39;pvalue&#39;</span><span class="p">)</span>

<span class="c1"># Create interactive plot.</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">interactive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils align-center">
<tbody>
<tr class="row-odd"><td><p><img alt="fig3a" src="_images/fig_cont_1.png" /></p></td>
</tr>
<tr class="row-even"><td><p><img alt="fig3b" src="_images/fig_cont_1b.png" /></p></td>
</tr>
</tbody>
</table>
<iframe src="https://erdogant.github.io/docs/d3blocks/bnlearn_continous_example_2.html" height="700px" width="750px", frameBorder="0"></iframe><p>There are various manners to deeper investigate the results such as looking at the CPDs.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print CPDs</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="s2">&quot;mpg&quot;</span><span class="p">))</span>
</pre></div>
</div>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>weight</p></td>
<td><p>…</p></td>
<td><p>weight((3657.5, 5140.0])</p></td>
</tr>
<tr class="row-even"><td><p>mpg((8.624, 15.25])</p></td>
<td><p>…</p></td>
<td><p>0.29931972789115646</p></td>
</tr>
<tr class="row-odd"><td><p>mpg((15.25, 17.65])</p></td>
<td><p>…</p></td>
<td><p>0.19727891156462582</p></td>
</tr>
<tr class="row-even"><td><p>mpg((17.65, 21.3])</p></td>
<td><p>…</p></td>
<td><p>0.13313896987366375</p></td>
</tr>
<tr class="row-odd"><td><p>mpg((21.3, 25.65])</p></td>
<td><p>…</p></td>
<td><p>0.12439261418853255</p></td>
</tr>
<tr class="row-even"><td><p>mpg((25.65, 28.9])</p></td>
<td><p>…</p></td>
<td><p>0.12439261418853255</p></td>
</tr>
<tr class="row-odd"><td><p>mpg((28.9, 46.6])</p></td>
<td><p>…</p></td>
<td><p>0.12147716229348882</p></td>
</tr>
</tbody>
</table>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Weight categories: &quot;</span><span class="p">,</span> <span class="n">df_disc</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>
<span class="c1"># Weight categories:  IntervalIndex([(1577.73, 2217.0], (2217.0, 2959.5], (2959.5, 3657.5], (3657.5, 5140.0]], dtype=&#39;interval[float64, right]&#39;)</span>
</pre></div>
</div>
</section>
<section id="inferences">
<h2>Inferences<a class="headerlink" href="#inferences" title="Link to this heading"></a></h2>
<p>Making inferences can be perfomred using the fitted model. Note that the evidence should be discretized for which we can
use the <code class="docutils literal notranslate"><span class="pre">discretize_value</span></code> function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">evidence</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="n">bn</span><span class="o">.</span><span class="n">discretize_value</span><span class="p">(</span><span class="n">df_discrete</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">],</span> <span class="mf">3000.0</span><span class="p">)}</span>
<span class="nb">print</span><span class="p">(</span><span class="n">evidence</span><span class="p">)</span>
<span class="c1"># {&#39;weight&#39;: Interval(2959.5, 3657.5, closed=&#39;right&#39;)}</span>

<span class="nb">print</span><span class="p">(</span><span class="n">bn</span><span class="o">.</span><span class="n">inference</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mpg&quot;</span><span class="p">],</span> <span class="n">evidence</span><span class="o">=</span><span class="n">evidence</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>mpg</p></th>
<th class="head"><p>phi(mpg)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>mpg((8.624, 15.25])</p></td>
<td><p>0.1510</p></td>
</tr>
<tr class="row-odd"><td><p>mpg((15.25, 17.65])</p></td>
<td><p>0.1601</p></td>
</tr>
<tr class="row-even"><td><p>mpg((17.65, 21.3])</p></td>
<td><p>0.2665</p></td>
</tr>
<tr class="row-odd"><td><p>mpg((21.3, 25.65])</p></td>
<td><p>0.1540</p></td>
</tr>
<tr class="row-even"><td><p>mpg((25.65, 28.9])</p></td>
<td><p>0.1327</p></td>
</tr>
<tr class="row-odd"><td><p>mpg((28.9, 46.6])</p></td>
<td><p>0.1358</p></td>
</tr>
</tbody>
</table>
<section id="references">
<h3>References<a class="headerlink" href="#references" title="Link to this heading"></a></h3>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id3" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Chen, Y.-C., Wheeler, T. A., &amp; Kochenderfer, M. J. (2015). Learning discrete Bayesian networks from continuous data. arXiv. <a class="reference external" href="https://arxiv.org/abs/1512.02406">https://arxiv.org/abs/1512.02406</a></p>
</aside>
<aside class="footnote brackets" id="id4" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>Julia 0.4 implementation. (n.d.). LearnDiscreteBayesNets.jl. <a class="reference external" href="https://github.com/sisl/LearnDiscreteBayesNets.jl">https://github.com/sisl/LearnDiscreteBayesNets.jl</a></p>
</aside>
</aside>
<hr>
<center>
        <script async src="https://media.ethicalads.io/media/client/ethicalads.min.js"></script>
        <!-- Show an image ad -->
        <!-- <div data-ea-publisher="erdogantgithubio" data-ea-type="image"></div> -->
        <div data-ea-publisher="erdogantgithubio" data-ea-type="image" data-ea-style="stickybox"></div>
</center>
<hr></section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Installation.html" class="btn btn-neutral float-left" title="Install from Pypi (pip)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Structure%20learning.html" class="btn btn-neutral float-right" title="Causation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Erdogan Taskesen.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>