<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Causation &mdash; bnlearn bnlearn documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Parameter learning" href="Parameter%20learning.html" />
    <link rel="prev" title="Installation" href="Installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> bnlearn
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
    
              <p class="caption" role="heading"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Quickstart.html">Quickstart</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html#validate">Validate</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html#uninstalling">Uninstalling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Structure learning</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Causation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#probability-theory">Probability theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="#structure-learning">Structure learning</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#exhaustivesearch">Exhaustivesearch</a></li>
<li class="toctree-l1"><a class="reference internal" href="#hillclimbsearch">Hillclimbsearch</a></li>
<li class="toctree-l1"><a class="reference internal" href="#chow-liu">Chow-liu</a></li>
<li class="toctree-l1"><a class="reference internal" href="#tree-augmented-naive-bayes-tan">Tree-augmented Naive Bayes (TAN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="#naivebayes">NaiveBayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="#constraint-based">Constraint-based</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parameter learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Parameter%20learning.html">Parameter learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Parameter%20learning.html#maximum-likelihood-estimation">Maximum Likelihood Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Parameter%20learning.html#bayesian-parameter-estimation">Bayesian Parameter Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Parameter%20learning.html#examples-parameter-learning">Examples Parameter learning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Inference.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="Inference.html#inference-algorithms">Inference Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="Inference.html#examples-inference">Examples Inference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Predict</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Predict.html">Predict</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other functionalities</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Create%20DAG.html">Directed Acyclic Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="Sampling%20and%20datasets.html">Sampling and datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="whitelist_blacklist.html">Black and white lists</a></li>
<li class="toctree-l1"><a class="reference internal" href="topological_sort.html">Topological sort</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataframe%20conversions.html">Data Conversions</a></li>
<li class="toctree-l1"><a class="reference internal" href="saving%20and%20loading.html">Saving and Loading</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Plot</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Plot.html">Interactive plot</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plot.html#static-plot">Static plot</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plot.html#comparison-of-two-networks">Comparison of two networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plot.html#node-properties">Node properties</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plot.html#edge-properties">Edge properties</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Examples.html">Various</a></li>
<li class="toctree-l1"><a class="reference internal" href="Examples.html#structure-learning">Structure learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Examples.html#parameter-learning">Parameter learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Examples.html#create-a-bayesian-network-learn-its-parameters-from-data-and-perform-the-inference">Create a Bayesian Network, learn its parameters from data and perform the inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="UseCases.html">Use Case Titanic</a></li>
<li class="toctree-l1"><a class="reference internal" href="UseCases.html#use-case-medical-domain">Use Case Medical domain</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html">Sponsor</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#advertising">Advertising</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#blog">Blog</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#github">Github</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#colab-notebook">Colab Notebook</a></li>
<li class="toctree-l1"><a class="reference internal" href="bnlearn.structure_learning.html">bnlearn.structure_learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="bnlearn.parameter_learning.html">bnlearn.parameter_learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="bnlearn.inference.html">bnlearn.inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="bnlearn.bnlearn.html">bnlearn.bnlearn</a></li>
</ul>

    <a href= "genindex.html">Index</a>
  
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">bnlearn</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Causation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/Structure learning.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="causation">
<h1>Causation<a class="headerlink" href="#causation" title="Permalink to this headline"></a></h1>
<p>Causation means that one (independent) variable causes the other (dependent) variable and is formulated by Reichenbach (1956) as follows:</p>
<p><em>If two random variables X and Y are statistically dependent (X/Y), then either (a) X causes Y, (b) Y causes X, or (c ) there exists a third variable Z that causes both X and Y. Further, X and Y become independent given Z, i.e., X⊥Y∣Z.</em></p>
<p>This definition is incorporated in Bayesian graphical models (a.k.a. Bayesian networks, Bayesian belief networks, Bayes Net, causal probabilistic networks, and Influence diagrams). A lot of names for the same technique. To determine causality, we can use Bayesian networks (BN). Let’s start with the graph and visualize the statistical dependencies between the three variables described by Reichenbach (X, Y, Z) (see figure below).
Nodes correspond to variables (X, Y, Z) and the directed edges (arrows) indicate dependency relationships or conditional distributions.</p>
<p><strong>But how can we tell what causes what?</strong>
The conceptual idea to determine the direction of causality, thus which node influences which node, is by holding a node constant and then observe the effect. As an example, let’s take DAG (a) in Figure 2, which describes that Z is caused by X, and Y is caused by Z. If we now keep Z constant there should not be a change in Y if this model is true. Every Bayesian network can be described by these four graphs, and with probability theory (see the section below) we can glue the parts together.
It should be noted that a Bayesian network is a Directed Acyclic Graph (DAG) and DAGs are causal. This means that the edges in the graph are directed and there is no (feedback) loop (acyclic).</p>
<figure class="align-default" id="fig-dags">
<img alt="_images/DAGs.png" src="_images/DAGs.png" />
</figure>
<p><em>DAGs encode conditional independencies. (a, b, c) are Equivalence classes. (a, b) Cascade, (c ) Common parent, and (d) is a special class with V-structure.</em></p>
<section id="probability-theory">
<h2>Probability theory<a class="headerlink" href="#probability-theory" title="Permalink to this headline"></a></h2>
<p>Probability theory, or more specific Bayes theorem or Bayes Rule, forms the fundament for Bayesian networks.
The Bayes rule is used to update model information, and stated mathematically as the underneath equation.</p>
<p>The equation consists of four parts; the posterior probability is the probability that Z occurs given X.
The conditional probability or likelihood is the probability of the evidence given that the hypothesis is true. This can be derived from the data.
Our prior belief is the probability of the hypothesis before observing the evidence. This can also be derived from the data or domain knowledge.
Finally, the marginal probability describes the probability of the new evidence under all possible hypotheses which needs to be computed.</p>
<figure class="align-default" id="bayes-eq">
<img alt="_images/bayes_eq.png" src="_images/bayes_eq.png" />
</figure>
</section>
<section id="structure-learning">
<h2>Structure learning<a class="headerlink" href="#structure-learning" title="Permalink to this headline"></a></h2>
<p>With structure learning, we want to determine the structure of the graph that best captures the causal dependencies between the variables in the data set.</p>
<p><strong>What is the DAG that best fits the data?</strong></p>
<p>A naïve manner to find the best DAG is simply creating all possible combinations of the graph,
i.e., by making tens, hundreds, or even thousands of different DAGs until all combinations are exhausted.
Each DAG can then be scored on the fit of the data. Finally, the best scoring DAG is returned.
In the case of variables X, Y, Z, one can make the graphs as shown below and a few more because it is not only X&gt;Z&gt;Y, but it can also be like Z&gt;X&gt;Y, etc.
The variables X, Y, Z can be boolean values (True or False), but can also have multiple states.</p>
<p>The search space of DAGs becomes so-called super-exponential in the number of variables that maximize the score.
This means that an exhaustive search is practically infeasible with a large number of nodes, and therefore,
various greedy strategies have been proposed to browse DAG space. With optimization-based search approaches, it is possible to browse a larger DAG space.
Such approaches require a scoring function and a search strategy. A common scoring function is the posterior probability of the structure given the training data, like the <em>BIC</em> or the <em>BDeu</em>.
Note that a local search strategy makes incremental changes aimed at improving the score of the structure. A global search algorithm like Markov chain Monte Carlo can avoid getting trapped in local minima but I will not discuss that here.</p>
<p>Approaches to search throughout the DAG space and find the best fitting graph for the data are implemented in <code class="docutils literal notranslate"><span class="pre">bnlearn</span></code>, and can be categorized under:</p>
<blockquote>
<div><ul class="simple">
<li><p>Score-based structure learning</p></li>
<li><p>Constraint-based structure learning</p></li>
<li><p>Hybrid structure learning</p></li>
</ul>
</div></blockquote>
<p>For score-based approaches there are two main components; <strong>1</strong>. The search algorithm to optimize throughout the search space of all possible DAGs; such as ExhaustiveSearch, Hillclimbsearch, Chow-Liu.
<strong>2</strong>. The scoring function indicates how well the Bayesian network fits the data. Commonly used scoring functions are Bayesian Dirichlet scores such as BDeu or K2 and the Bayesian Information Criterion (BIC, also called MDL).
<code class="docutils literal notranslate"><span class="pre">bnlearn</span></code> contains the following <em>Score-based structure learning</em> methods:</p>
<blockquote>
<div><ul class="simple">
<li><p>Exhaustivesearch</p></li>
<li><p>Hillclimbsearch</p></li>
<li><p>Chow-liu</p></li>
<li><p>Tree-augmented Naive Bayes (TAN)</p></li>
<li><p>NaiveBayes</p></li>
</ul>
</div></blockquote>
<p>Each approach can be scored using the following scoretypes:</p>
<blockquote>
<div><ul class="simple">
<li><p>bic</p></li>
<li><p>k2</p></li>
<li><p>bdeu</p></li>
</ul>
</div></blockquote>
</section>
</section>
<section id="exhaustivesearch">
<h1>Exhaustivesearch<a class="headerlink" href="#exhaustivesearch" title="Permalink to this headline"></a></h1>
<p>The <em>ExhaustiveSearch</em> approach scores every possible DAG and returns the best-scoring DAG.
This search approach is only attractable for very small networks and prohibits efficient local optimization algorithms to always find the optimal structure. Thus, identifying the ideal structure is often not tractable. Nevertheless, heuristic search strategies often yield good results if only a few nodes are involved (read: less than 5 or so).</p>
<p>Lets determine the best possible structure for the sprinkler dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load library</span>
<span class="kn">import</span> <span class="nn">bnlearn</span> <span class="k">as</span> <span class="nn">bn</span>
<span class="c1"># Load example</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">import_example</span><span class="p">(</span><span class="s1">&#39;sprinkler&#39;</span><span class="p">)</span>
<span class="c1"># Structure learning</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">structure_learning</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">methodtype</span><span class="o">=</span><span class="s1">&#39;ex&#39;</span><span class="p">,</span> <span class="n">scoretype</span><span class="o">=</span><span class="s1">&#39;bic&#39;</span><span class="p">)</span>
<span class="c1"># Compute edge strength using chi-square independence test and remove (prune) the not-signficant edges</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">independence_test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">prune</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Examine the output of the chi-square test. All P values are significant. Nothing is removed.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">model</span><span class="p">[</span><span class="s1">&#39;independence_test&#39;</span><span class="p">],</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;grid&quot;</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">&quot;keys&quot;</span><span class="p">))</span>
<span class="c1">#    source     target     stat_test        p_value    chi_square    dof</span>
<span class="c1">#--  ---------  ---------  -----------  -----------  ------------  -----</span>
<span class="c1"># 0  Cloudy     Rain       True         1.08061e-87       394.062      1</span>
<span class="c1"># 1  Cloudy     Sprinkler  True         8.38371e-53       233.906      1</span>
<span class="c1"># 2  Rain       Wet_Grass  True         3.88651e-64       285.902      1</span>
<span class="c1"># 3  Sprinkler  Wet_Grass  True         1.19692e-23       100.478      1</span>

<span class="c1"># Plot</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils align-center" id="id1">
<caption><span class="caption-text">Exhaustivesearch example</span><a class="headerlink" href="#id1" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="_images/exhaustivesearch_example.png"><img alt="exh1" src="_images/exhaustivesearch_example.png" style="width: 851.0px; height: 449.0px;" /></a></p></td>
</tr>
</tbody>
</table>
</section>
<section id="hillclimbsearch">
<h1>Hillclimbsearch<a class="headerlink" href="#hillclimbsearch" title="Permalink to this headline"></a></h1>
<p><em>Hillclimbsearch</em> is a heuristic search approach that can be used if more nodes are used. HillClimbSearch implements a greedy local search that starts from the DAG “start” (default: disconnected DAG) and proceeds by iteratively performing single-edge manipulations that maximally increase the score. The search terminates once a local maximum is found.
With <em>Hillclimbsearch</em> we can determine the best DAG for multiple nodes.</p>
<p>Lets examine the results using hte <strong>alarm</strong> example that contains 37 nodes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load library</span>
<span class="kn">import</span> <span class="nn">bnlearn</span> <span class="k">as</span> <span class="nn">bn</span>
<span class="c1"># Load example</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">import_example</span><span class="p">(</span><span class="s1">&#39;alarm&#39;</span><span class="p">)</span>
<span class="c1"># Structure learning</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">structure_learning</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">methodtype</span><span class="o">=</span><span class="s1">&#39;hc&#39;</span><span class="p">,</span> <span class="n">scoretype</span><span class="o">=</span><span class="s1">&#39;bic&#39;</span><span class="p">)</span>
<span class="c1"># Plot detected DAG</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># Compute edge strength using chi-square independence test</span>
<span class="n">model1</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">independence_test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">prune</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">G</span><span class="p">[</span><span class="s1">&#39;pos&#39;</span><span class="p">])</span>

<span class="c1"># Examine the output of the chi-square test. 53 edges are detected but not all P values are significant, i.e. those with stat_test=False</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">model1</span><span class="p">[</span><span class="s1">&#39;independence_test&#39;</span><span class="p">],</span> <span class="n">headers</span><span class="o">=</span><span class="s2">&quot;keys&quot;</span><span class="p">))</span>
<span class="c1">#    source        target        stat_test         p_value    chi_square    dof</span>
<span class="c1">#--  ------------  ------------  -----------  ------------  ------------  -----</span>
<span class="c1"># 0  LVFAILURE     HISTORY       True         0               7179.51         1</span>
<span class="c1"># 1  LVEDVOLUME    CVP           True         0              12510.3          4</span>
<span class="c1"># 2  LVEDVOLUME    HYPOVOLEMIA   True         0               6421.13         2</span>
<span class="c1"># 3  LVEDVOLUME    LVFAILURE     True         0               5240.09         2</span>
<span class="c1"># 4  PCWP          LVEDVOLUME    True         0              15718.7          4</span>
<span class="c1"># 5  STROKEVOLUME  PCWP          True         0               1683.67         4</span>
<span class="c1"># 6  STROKEVOLUME  CO            True         0               6848.73         4</span>
<span class="c1"># 7  STROKEVOLUME  LVFAILURE     True         0               2083.49         2</span>
<span class="c1"># 8  STROKEVOLUME  HYPOVOLEMIA   True         0               1810.87         2</span>
<span class="c1"># 9  STROKEVOLUME  LVEDVOLUME    True         0               2221.26         4</span>
<span class="c1">#10  ERRLOWOUTPUT  HRBP          True         0               5828.4          2</span>
<span class="c1">#11  HR            HREKG         True         0               8306.22         4</span>
<span class="c1">#12  HR            CO            True         0               5444.03         4</span>
<span class="c1">#13  HR            HRSAT         True         0               8450.71         4</span>
<span class="c1">#14  HR            HRBP          True         0               9205.59         4</span>
<span class="c1">#15  ERRCAUTER     HREKG         True         0               7081.32         2</span>
<span class="c1">#16  ERRCAUTER     HRSAT         True         0               7126.75         2</span>
<span class="c1">#17  HREKG         HRSAT         True         0              14283.5          4</span>
<span class="c1">#18  TPR           BP            True         0               5639.01         4</span>
<span class="c1">#19  TPR           ANAPHYLAXIS   True         2.06818e-54      247.226        2</span>
<span class="c1">#20  ARTCO2        EXPCO2        True         2.02465e-308    1441.92         6</span>
<span class="c1">#21  ARTCO2        CATECHOL      True         1.6471e-265     1219.37         2</span>
<span class="c1">#22  ARTCO2        TPR           False        0.71824            2.09528      4</span>
<span class="c1">#23  VENTLUNG      EXPCO2        True         0               9159.91         9</span>
<span class="c1">#24  VENTLUNG      MINVOL        True         0              10273.7          9</span>
<span class="c1">#25  VENTLUNG      KINKEDTUBE    True         1.75631e-26      122.985        3</span>
<span class="c1">#26  INTUBATION    SHUNT         True         0               4154.53         2</span>
<span class="c1">#27  INTUBATION    VENTLUNG      True         4.45141e-71      343.198        6</span>
<span class="c1">#28  INTUBATION    PRESS         True         2.65747e-161     761.872        6</span>
<span class="c1">#29  INTUBATION    MINVOL        True         0               4453.48         6</span>
<span class="c1">#30  FIO2          PVSAT         True         6.37291e-152     696.282        2</span>
<span class="c1">#31  PVSAT         VENTALV       True         0               9573.62         6</span>
<span class="c1">#32  PVSAT         SAO2          True         0              12841.4          4</span>
<span class="c1">#33  VENTALV       ARTCO2        True         0              14150.2          6</span>
<span class="c1">#34  VENTALV       MINVOL        True         0              15664            9</span>
<span class="c1">#35  VENTALV       VENTLUNG      True         0              12209.5          9</span>
<span class="c1">#36  VENTALV       INTUBATION    True         0               5476.61         6</span>
<span class="c1">#37  SHUNT         SAO2          True         6.09174e-48      217.434        2</span>
<span class="c1">#38  PULMEMBOLUS   SHUNT         True         8.36791e-157     711.741        1</span>
<span class="c1">#39  PULMEMBOLUS   PAP           True         1.07736e-243    1118.91         2</span>
<span class="c1">#40  PULMEMBOLUS   ERRLOWOUTPUT  True         0.0345358          4.46798      1</span>
<span class="c1">#41  KINKEDTUBE    PRESS         True         5.55643e-211     974.694        3</span>
<span class="c1">#42  VENTTUBE      PVSAT         True         0               4643.05         6</span>
<span class="c1">#43  VENTTUBE      PRESS         True         0               2834.42         9</span>
<span class="c1">#44  VENTTUBE      VENTALV       True         0               6157.26         9</span>
<span class="c1">#45  VENTTUBE      INTUBATION    False        0.548197           4.96588      6</span>
<span class="c1">#46  VENTTUBE      KINKEDTUBE    False        0.476625           2.49263      3</span>
<span class="c1">#47  MINVOLSET     VENTMACH      True         0              15374.5          6</span>
<span class="c1">#48  VENTMACH      VENTTUBE      True         0              12278.4          9</span>
<span class="c1">#49  DISCONNECT    VENTTUBE      True         0               3926.11         3</span>
<span class="c1">#50  CATECHOL      TPR           True         0               1813.11         2</span>
<span class="c1">#51  CATECHOL      HR            True         0               4253.1          2</span>
<span class="c1">#52  CO            BP            True         0               2246.32         4</span>

<span class="c1"># Compute edge strength using chi-square independence test and remove (prune) the not-signficant edges</span>
<span class="n">model3</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">independence_test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">prune</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model3</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">G</span><span class="p">[</span><span class="s1">&#39;pos&#39;</span><span class="p">])</span>
</pre></div>
</div>
<table class="docutils align-center" id="id2">
<caption><span class="caption-text">Hillclimbsearch. (A) Detected DAG. (B) DAG with significance. (C) DAG pruned.</span><a class="headerlink" href="#id2" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><img alt="hill1" src="_images/Hillclimbsearch1.png" /></p></td>
<td><p><img alt="hill2" src="_images/Hillclimbsearch2.png" /></p></td>
<td><p><img alt="hill3" src="_images/Hillclimbsearch3.png" /></p></td>
</tr>
</tbody>
</table>
</section>
<section id="chow-liu">
<h1>Chow-liu<a class="headerlink" href="#chow-liu" title="Permalink to this headline"></a></h1>
<p>The <em>Chow-Liu</em> Algorithm is a Tree search based approach which finds the maximum-likelihood tree structure where each node has at most one parent.
The complexity can be limited by restricting to tree structures which makes this approach very fast to determine the DAG using large datasets (aka with many variables) but requires setting a <strong>root node</strong>.</p>
<p>The Chow-Liu algorithm has three steps:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Compute the mutual information for all pairs of variables X,U. This function measures how much information U provides about X</p></li>
<li><p>Find the maximum weight spanning tree: the maximal-weight tree that connects all vertices in a graph. This can be found using Kruskal or Prim Algorithms</p></li>
<li><p>Pick any node to be the root variable, and assign directions radiating outward from this node (arrows go away from it). This step transforms the resulting undirected tree to a directed one.</p></li>
</ol>
</div></blockquote>
<p>Lets determine the best possible structure for the <em>titanic</em> dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load library</span>
<span class="kn">import</span> <span class="nn">bnlearn</span> <span class="k">as</span> <span class="nn">bn</span>
<span class="c1"># Load example</span>
<span class="n">df_raw</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">import_example</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="s1">&#39;titanic&#39;</span><span class="p">)</span>
<span class="c1"># Preprocessing raw dataset</span>
<span class="n">dfhot</span><span class="p">,</span> <span class="n">dfnum</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">df2onehot</span><span class="p">(</span><span class="n">df_raw</span><span class="p">)</span>

<span class="c1"># Structure learning</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">structure_learning</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dfnum</span><span class="p">,</span> <span class="n">methodtype</span><span class="o">=</span><span class="s1">&#39;cl&#39;</span><span class="p">,</span> <span class="n">black_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Embarked&#39;</span><span class="p">,</span><span class="s1">&#39;Parch&#39;</span><span class="p">,</span><span class="s1">&#39;Name&#39;</span><span class="p">],</span> <span class="n">root_node</span><span class="o">=</span><span class="s1">&#39;Survived&#39;</span><span class="p">,</span> <span class="n">bw_list_method</span><span class="o">=</span><span class="s1">&#39;nodes&#39;</span><span class="p">)</span>
<span class="c1"># Plot detected DAG</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># Compute edge strength using chi-square independence test and remove (prune) the not-signficant edges</span>
<span class="n">model1</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">independence_test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dfnum</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">prune</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># [bnlearn] &gt;Edge [Ticket &lt;-&gt; Sex] [P=0.714624] is excluded because it was not significant (P&lt;0.05) with [chi_square]</span>

<span class="c1"># Plot</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">G</span><span class="p">[</span><span class="s1">&#39;pos&#39;</span><span class="p">])</span>
</pre></div>
</div>
<table class="docutils align-center" id="id3">
<caption><span class="caption-text">Chow-Liu. (A) Detected DAG. (B) DAG pruned on significance.</span><a class="headerlink" href="#id3" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><img alt="chow1" src="_images/Chow1.png" /></p></td>
<td><p><img alt="chow2" src="_images/Chow2.png" /></p></td>
</tr>
</tbody>
</table>
</section>
<section id="tree-augmented-naive-bayes-tan">
<h1>Tree-augmented Naive Bayes (TAN)<a class="headerlink" href="#tree-augmented-naive-bayes-tan" title="Permalink to this headline"></a></h1>
<p>Tree-augmented Naive Bayes (TAN) algorithm is also a tree-based approach that can be used to model huge datasets involving lots of uncertainties among its various interdependent feature sets.
It relaxes the naive Bayes attribute independence assumption by employing a tree structure, in which each attribute only depends on the class and one other attribute.
A maximum weighted spanning tree that maximizes the likelihood of the training data is used to perform classification.</p>
<p>TAN has three steps:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Approximate the dependencies among features with a tree Bayes net.</p></li>
<li><dl class="simple">
<dt>Tree induction algorithm</dt><dd><ul class="simple">
<li><p>Optimality: Maximum likelihood tree</p></li>
<li><p>Efficiency: Polynomial algorithm</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Robust parameter estimation</p></li>
</ol>
</div></blockquote>
<p>Lets determine the best possible structure for the <em>asia</em> dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load library</span>
<span class="kn">import</span> <span class="nn">bnlearn</span> <span class="k">as</span> <span class="nn">bn</span>
<span class="c1"># Load example</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">import_example</span><span class="p">(</span><span class="s1">&#39;asia&#39;</span><span class="p">)</span>

<span class="c1"># Structure learning</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">structure_learning</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">methodtype</span><span class="o">=</span><span class="s1">&#39;tan&#39;</span><span class="p">,</span> <span class="n">class_node</span><span class="o">=</span><span class="s1">&#39;lung&#39;</span><span class="p">)</span>
<span class="c1"># Plot detected DAG</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># Compute edge strength using chi-square independence test</span>
<span class="n">model1</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">independence_test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">prune</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">G</span><span class="p">[</span><span class="s1">&#39;pos&#39;</span><span class="p">])</span>

<span class="c1"># Examine the output of the chi-square test. 13 edges are detected but not all P values are significant, i.e. those with stat_test=False</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">model1</span><span class="p">[</span><span class="s1">&#39;independence_test&#39;</span><span class="p">],</span> <span class="n">headers</span><span class="o">=</span><span class="s2">&quot;keys&quot;</span><span class="p">))</span>
<span class="c1">#    source    target    stat_test         p_value    chi_square    dof</span>
<span class="c1">#--  --------  --------  -----------  ------------  ------------  -----</span>
<span class="c1"># 0  either    xray      True         0               5589.38         1</span>
<span class="c1"># 1  either    tub       True         5.36195e-294    1342.91         1</span>
<span class="c1"># 2  either    dysp      True         2.82344e-85      382.959        1</span>
<span class="c1"># 3  tub       asia      False        0.104413           2.63681      1</span>
<span class="c1"># 4  dysp      bronc     True         0               4737.06         1</span>
<span class="c1"># 5  bronc     smoke     True         1.0335e-211      964.3          1</span>
<span class="c1"># 6  lung      asia      False        1                  0            1</span>
<span class="c1"># 7  lung      tub       False        0.125939           2.34186      1</span>
<span class="c1"># 8  lung      smoke     True         3.70391e-91      409.979        1</span>
<span class="c1"># 9  lung      bronc     True         1.90616e-09       36.0673       1</span>
<span class="c1">#10  lung      either    True         0               8604.76         1</span>
<span class="c1">#11  lung      xray      True         0               4800.25         1</span>
<span class="c1">#12  lung      dysp      True         1.34994e-76      343.097        1</span>

<span class="c1"># Compute edge strength using chi-square independence test and remove (prune) the not-signficant edges</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">independence_test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">prune</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># [bnlearn] &gt;Edge [tub &lt;-&gt; asia] [P=0.104413] is excluded because it was not significant (P&lt;0.05) with [chi_square]</span>
<span class="c1"># [bnlearn] &gt;Edge [lung &lt;-&gt; asia] [P=1] is excluded because it was not significant (P&lt;0.05) with [chi_square]</span>
<span class="c1"># [bnlearn] &gt;Edge [lung &lt;-&gt; tub] [P=0.125939] is excluded because it was not significant (P&lt;0.05) with [chi_square]</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model2</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">G</span><span class="p">[</span><span class="s1">&#39;pos&#39;</span><span class="p">])</span>
</pre></div>
</div>
<table class="docutils align-center" id="id4">
<caption><span class="caption-text">Tree-augmented Naive Bayes. (A) Detected DAG. (B) DAG depicting significance. (C) DAG pruned.</span><a class="headerlink" href="#id4" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><img alt="tan1" src="_images/tan1.png" /></p></td>
<td><p><img alt="tan2" src="_images/tan2.png" /></p></td>
<td><p><img alt="tan3" src="_images/tan3.png" /></p></td>
</tr>
</tbody>
</table>
</section>
<section id="naivebayes">
<h1>NaiveBayes<a class="headerlink" href="#naivebayes" title="Permalink to this headline"></a></h1>
<p>Naive Bayes is a special case of Bayesian Model where the only edges in the model are from the feature variables to the dependent variable.</p>
<p>The method requires specifying:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>The root node.</p></li>
<li><p>Edges should start from the root node.</p></li>
<li><p>MaximumLikelihood estimator is the default.</p></li>
</ol>
</div></blockquote>
<p>Example to design a DAG with the naivebayes model:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load library</span>
<span class="kn">from</span> <span class="nn">pgmpy.factors.discrete</span> <span class="kn">import</span> <span class="n">TabularCPD</span>
<span class="kn">import</span> <span class="nn">bnlearn</span> <span class="k">as</span> <span class="nn">bn</span>

<span class="c1"># Create some edges, all starting from the same root node: A</span>
<span class="n">edges</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;D&#39;</span><span class="p">)]</span>
<span class="n">DAG</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">make_DAG</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">methodtype</span><span class="o">=</span><span class="s1">&#39;naivebayes&#39;</span><span class="p">)</span>

<span class="c1"># Set CPDs</span>
<span class="n">cpd_A</span> <span class="o">=</span> <span class="n">TabularCPD</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">variable_card</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.3</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">]])</span>
<span class="n">cpd_B</span> <span class="o">=</span> <span class="n">TabularCPD</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">variable_card</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]],</span> <span class="n">evidence</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="n">evidence_card</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">cpd_C</span> <span class="o">=</span> <span class="n">TabularCPD</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="n">variable_card</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]],</span> <span class="n">evidence</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="n">evidence_card</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">cpd_D</span> <span class="o">=</span> <span class="n">TabularCPD</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="n">variable_card</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]],</span> <span class="n">evidence</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="n">evidence_card</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="c1"># Make the DAG</span>
<span class="n">DAG</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">make_DAG</span><span class="p">(</span><span class="n">DAG</span><span class="p">,</span> <span class="n">CPD</span><span class="o">=</span><span class="p">[</span><span class="n">cpd_A</span><span class="p">,</span> <span class="n">cpd_B</span><span class="p">,</span> <span class="n">cpd_C</span><span class="p">,</span> <span class="n">cpd_D</span><span class="p">],</span> <span class="n">checkmodel</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># Plot the CPDs as a sanity check</span>
<span class="n">bn</span><span class="o">.</span><span class="n">print_CPD</span><span class="p">(</span><span class="n">DAG</span><span class="p">,</span> <span class="n">checkmodel</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># Plot the DAG</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">DAG</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-default" id="fig-naivebayes-1">
<img alt="_images/naivebayes_example1.png" src="_images/naivebayes_example1.png" />
</figure>
<p>Example for structure learning with the naivebayes model:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load library</span>
<span class="kn">import</span> <span class="nn">bnlearn</span> <span class="k">as</span> <span class="nn">bn</span>
<span class="c1"># Load example</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">import_example</span><span class="p">(</span><span class="s1">&#39;random&#39;</span><span class="p">)</span>
<span class="c1"># Structure learning</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">structure_learning</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">methodtype</span><span class="o">=</span><span class="s1">&#39;naivebayes&#39;</span><span class="p">,</span> <span class="n">root_node</span><span class="o">=</span><span class="s2">&quot;B&quot;</span><span class="p">)</span>
<span class="c1"># Compute edge strength using chi-square independence test</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">independence_test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">prune</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># Plot</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># Prune using the chi-square independence test</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">independence_test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">prune</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># [bnlearn] &gt;Compute edge strength with [chi_square]</span>
<span class="c1"># [bnlearn] &gt;Edge [B &lt;-&gt; A] [P=0.240783] is excluded because it was not significant (P&lt;0.05) with [chi_square]</span>
<span class="c1"># [bnlearn] &gt;Edge [B &lt;-&gt; C] [P=0.766384] is excluded because it was not significant (P&lt;0.05) with [chi_square]</span>
<span class="c1"># [bnlearn] &gt;Edge [B &lt;-&gt; D] [P=0.382504] is excluded because it was not significant (P&lt;0.05) with [chi_square]</span>
<span class="c1"># Plot</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils align-center" id="id5">
<caption><span class="caption-text">Naivebayes Example without and with pruning using chi2 test</span><a class="headerlink" href="#id5" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><img alt="logo1" src="_images/naivebayes_example2.png" /></p></td>
<td><p><img alt="logo2" src="_images/naivebayes_example21.png" /></p></td>
</tr>
</tbody>
</table>
</section>
<section id="constraint-based">
<h1>Constraint-based<a class="headerlink" href="#constraint-based" title="Permalink to this headline"></a></h1>
<p>A different, but quite straightforward approach to build a DAG from data is to identify independencies in the data set using hypothesis tests, such as chi2 test statistic. The p_value of the test, and a heuristig flag that indicates if the sample size was sufficient. The p_value is the probability of observing the computed chi2 statistic (or an even higher chi2 value), given the null hypothesis that X and Y are independent given Zs. This can be used to make independence judgements, at a given level of significance.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Hypothesis tests</p></li>
<li><p>Construct DAG (pattern) according to identified independencies (Conditional) Independence Tests</p></li>
<li><p>Independencies in the data can be identified using chi2 conditional independence tests.</p></li>
</ol>
</div></blockquote>
<p>Lets determine the best possible structure for the <em>water</em> dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load library</span>
<span class="kn">import</span> <span class="nn">bnlearn</span> <span class="k">as</span> <span class="nn">bn</span>
<span class="c1"># Load example</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">import_example</span><span class="p">(</span><span class="s1">&#39;water&#39;</span><span class="p">)</span>

<span class="c1"># Structure learning</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">structure_learning</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">methodtype</span><span class="o">=</span><span class="s1">&#39;cs&#39;</span><span class="p">)</span>
<span class="c1"># Plot detected DAG</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># Compute edge strength using chi-square independence test</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bn</span><span class="o">.</span><span class="n">independence_test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">prune</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">bn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">G</span><span class="p">[</span><span class="s1">&#39;pos&#39;</span><span class="p">])</span>
</pre></div>
</div>
<table class="docutils align-center" id="id6">
<caption><span class="caption-text">Constraint-based. (A) Detected DAG. (B) DAG depicting significance.</span><a class="headerlink" href="#id6" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><img alt="const1" src="_images/const1.png" /></p></td>
<td><p><img alt="const2" src="_images/const2.png" /></p></td>
</tr>
</tbody>
</table>
<p><strong>References</strong></p>
<blockquote>
<div><ol class="arabic simple">
<li><p><a class="reference external" href="https://ermongroup.github.io/cs228-notes/learning/structure/">https://ermongroup.github.io/cs228-notes/learning/structure/</a></p></li>
<li><p><a class="reference external" href="https://doi.org/10.1007/978-0-387-30164-8_850">https://doi.org/10.1007/978-0-387-30164-8_850</a></p></li>
</ol>
</div></blockquote>
<hr>
<center>
        <script async type="text/javascript" src="//cdn.carbonads.com/carbon.js?serve=CEADP27U&placement=erdogantgithubio" id="_carbonads_js"></script>
</center>
<hr></section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Installation.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Parameter%20learning.html" class="btn btn-neutral float-right" title="Parameter learning" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Erdogan Taskesen.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>